{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#from torchsummary import summary\n",
    "STEP =256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7676, 18176, 1) (7676, 71)\n"
     ]
    }
   ],
   "source": [
    "#Padded input data , labels are arrays which are also padded to maximum size , \n",
    "#its not one hot encoded. \n",
    "data = np.load('train.npz')\n",
    "train_x = data['a']\n",
    "train_y = data['b']\n",
    "print(train_x.shape,train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just an generator for training.\n",
    "def data_generator(batch_size, x, y):\n",
    "    num_examples = len(x)\n",
    "    examples = zip(x, y)\n",
    "    examples = sorted(examples, key = lambda x: x[0].shape[0])\n",
    "    end = num_examples - batch_size + 1\n",
    "    batches = [examples[i:i+batch_size]\n",
    "                for i in range(0, end, batch_size)]\n",
    "    random.shuffle(batches)\n",
    "    batchlen = int(len(batches))\n",
    "  \n",
    "    i =0\n",
    "    while True:\n",
    "\n",
    "        if i >= batchlen:\n",
    "               return\n",
    "        #print(i)\n",
    "        x, y = zip(*batches[i])\n",
    "        yield np.asarray(x), np.asarray(y)\n",
    "        i = i +1\n",
    "        \n",
    "            #yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bn_Relu(nn.Module):\n",
    "    def __init__(self, output,dropout=0):\n",
    "        super(Bn_Relu,self).__init__()\n",
    "        self.bn =  nn.BatchNorm1d(output)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop = None\n",
    "        if dropout > 0:\n",
    "           self.drop = nn.Dropout(dropout)\n",
    "    def forward(self,x):\n",
    "        out = self.bn(x)\n",
    "        out = self.relu(out)\n",
    "        if self.drop is not None:\n",
    "            out = self.drop(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padding(requiredSize, originalSize):\n",
    "    x = requiredSize - originalSize\n",
    "    if x % 2 == 0:\n",
    "        return (int(x/2) ,int(x/2))\n",
    "    else:\n",
    "        x = int(x/2)\n",
    "        return (x+1,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self,prev_filters,num_filters,subsample_length,block_index,dropout):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.subsample_length = subsample_length\n",
    "        self.max1 = nn.MaxPool1d(kernel_size=subsample_length)\n",
    "        self.zero_pad = (block_index % 4) == 0 and block_index > 0\n",
    "        #if zero_pad is True:\n",
    "            #shortcut = Lambda(zeropad, output_shape=zeropad_output_shape)(shortcut)\n",
    "        print(\"Conv 1\" ,prev_filters,num_filters,subsample_length)\n",
    "        self.conv1 = nn.Conv1d(prev_filters, num_filters, 16, subsample_length)\n",
    "        self.bn1 = None\n",
    "        if(block_index !=0):\n",
    "              self.bn1 = Bn_Relu(num_filters, dropout )\n",
    "        print(\"Conv 2\" ,num_filters)\n",
    "        self.conv2 = nn.Conv1d(num_filters, num_filters,16, 1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        iden = self.max1(x)\n",
    "                       \n",
    "              \n",
    "        out = self.conv1(x)\n",
    "        if self.bn1 is not None:\n",
    "            out = self.bn1(out)\n",
    "        out = self.conv2(out)\n",
    "        #print (\"out Before \",out.shape,iden.shape)\n",
    "        if(iden.shape[2] != out.shape[2]):\n",
    "            #convSize = ((out.shape[2] - (16-1)-1)/self.subsample_length) +1\n",
    "            #convSize = int(convSize)\n",
    "            p1d = get_padding(iden.shape[2],out.shape[2])\n",
    "            #print (\"paddings\",p1d)\n",
    "            out = F.pad(out, p1d, \"constant\", 0) \n",
    "            #print (\"out After\",out.shape[2])\n",
    "        if(iden.shape[1] < out.shape[1]):\n",
    "            #print(\"shape of middle\",out.shape[1],iden.shape[1])\n",
    "            xpad = (0,0)\n",
    "            xpad = xpad + get_padding(out.shape[1],iden.shape[1])\n",
    "            #print (\"x paddings\",xpad)\n",
    "            iden = F.pad(iden, xpad, \"constant\", 0) \n",
    "            #print (\"iden After\",iden.shape[1])\n",
    "           \n",
    "        out += iden\n",
    "        return out       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_filters_at_index(index, num_start_filters):\n",
    "    return 2**int(index / 4) \\\n",
    "        * num_start_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self,dropout):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.layers1 = nn.Conv1d(1, 32, 16, 1)\n",
    "        self.bn1 = Bn_Relu(32)\n",
    "        layers = []\n",
    "        res = [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2]\n",
    "        #res = [1,2,1]\n",
    "        prev_filter =32\n",
    "        self.debug =0;\n",
    "        for index, subsample_length in enumerate(res):\n",
    "            num_filters = get_num_filters_at_index(index, 32 )\n",
    "            print(\"filter length\",prev_filter,num_filters)\n",
    "            x =  ResnetBlock(prev_filter,num_filters,subsample_length,index,dropout)\n",
    "            y = Bn_Relu(num_filters,dropout)\n",
    "            prev_filter = num_filters\n",
    "            layers.append(x)\n",
    "            layers.append(y)\n",
    "        self.resLayer = nn.Sequential(*layers)\n",
    "        self.linear1 = nn.Linear(256,4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(self.debug)\n",
    "        self.debug +=1\n",
    "        x= self.layers1(x)\n",
    "        x= self.bn1(x)\n",
    "        x = self.resLayer(x)\n",
    "        x = F.pad(x, (0,1), \"constant\", 0) \n",
    "        x = x.permute(0,2,1)\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        #y = x.view(x.size()[0], -1);\n",
    "        #print (\"final shape \", x.shape)\n",
    "        #return F.log_softmax(self.linear1(x.view(x.size()[0], -1)), dim=1)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        #return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajee\\AppData\\Local\\Continuum\\anaconda3\\envs\\fresh\\lib\\site-packages\\torch\\nn\\_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "loss_fn = nn.CrossEntropyLoss(size_average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter length 32 32\n",
      "Conv 1 32 32 1\n",
      "Conv 2 32\n",
      "filter length 32 32\n",
      "Conv 1 32 32 2\n",
      "Conv 2 32\n",
      "filter length 32 32\n",
      "Conv 1 32 32 1\n",
      "Conv 2 32\n",
      "filter length 32 32\n",
      "Conv 1 32 32 2\n",
      "Conv 2 32\n",
      "filter length 32 64\n",
      "Conv 1 32 64 1\n",
      "Conv 2 64\n",
      "filter length 64 64\n",
      "Conv 1 64 64 2\n",
      "Conv 2 64\n",
      "filter length 64 64\n",
      "Conv 1 64 64 1\n",
      "Conv 2 64\n",
      "filter length 64 64\n",
      "Conv 1 64 64 2\n",
      "Conv 2 64\n",
      "filter length 64 128\n",
      "Conv 1 64 128 1\n",
      "Conv 2 128\n",
      "filter length 128 128\n",
      "Conv 1 128 128 2\n",
      "Conv 2 128\n",
      "filter length 128 128\n",
      "Conv 1 128 128 1\n",
      "Conv 2 128\n",
      "filter length 128 128\n",
      "Conv 1 128 128 2\n",
      "Conv 2 128\n",
      "filter length 128 256\n",
      "Conv 1 128 256 1\n",
      "Conv 2 256\n",
      "filter length 256 256\n",
      "Conv 1 256 256 2\n",
      "Conv 2 256\n",
      "filter length 256 256\n",
      "Conv 1 256 256 1\n",
      "Conv 2 256\n",
      "filter length 256 256\n",
      "Conv 1 256 256 2\n",
      "Conv 2 256\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(dropout =0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (layers1): Conv1d(1, 32, kernel_size=(16,), stride=(1,))\n",
       "  (bn1): Bn_Relu(\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (resLayer): Sequential(\n",
       "    (0): ResnetBlock(\n",
       "      (max1): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv1): Conv1d(32, 32, kernel_size=(16,), stride=(1,))\n",
       "      (conv2): Conv1d(32, 32, kernel_size=(16,), stride=(1,))\n",
       "    )\n",
       "    (1): Bn_Relu(\n",
       "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (drop): Dropout(p=0.2)\n",
       "    )\n",
       "    (2): ResnetBlock(\n",
       "      (max1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv1): Conv1d(32, 32, kernel_size=(16,), stride=(2,))\n",
       "      (bn1): Bn_Relu(\n",
       "        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "      (conv2): Conv1d(32, 32, kernel_size=(16,), stride=(1,))\n",
       "    )\n",
       "    (3): Bn_Relu(\n",
       "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (drop): Dropout(p=0.2)\n",
       "    )\n",
       "    (4): ResnetBlock(\n",
       "      (max1): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv1): Conv1d(32, 32, kernel_size=(16,), stride=(1,))\n",
       "      (bn1): Bn_Relu(\n",
       "        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "      (conv2): Conv1d(32, 32, kernel_size=(16,), stride=(1,))\n",
       "    )\n",
       "    (5): Bn_Relu(\n",
       "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (drop): Dropout(p=0.2)\n",
       "    )\n",
       "    (6): ResnetBlock(\n",
       "      (max1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv1): Conv1d(32, 32, kernel_size=(16,), stride=(2,))\n",
       "      (bn1): Bn_Relu(\n",
       "        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "      (conv2): Conv1d(32, 32, kernel_size=(16,), stride=(1,))\n",
       "    )\n",
       "    (7): Bn_Relu(\n",
       "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (drop): Dropout(p=0.2)\n",
       "    )\n",
       "    (8): ResnetBlock(\n",
       "      (max1): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv1): Conv1d(32, 64, kernel_size=(16,), stride=(1,))\n",
       "      (bn1): Bn_Relu(\n",
       "        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(16,), stride=(1,))\n",
       "    )\n",
       "    (9): Bn_Relu(\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (drop): Dropout(p=0.2)\n",
       "    )\n",
       "    (10): ResnetBlock(\n",
       "      (max1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv1): Conv1d(64, 64, kernel_size=(16,), stride=(2,))\n",
       "      (bn1): Bn_Relu(\n",
       "        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(16,), stride=(1,))\n",
       "    )\n",
       "    (11): Bn_Relu(\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (drop): Dropout(p=0.2)\n",
       "    )\n",
       "    (12): ResnetBlock(\n",
       "      (max1): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv1): Conv1d(64, 64, kernel_size=(16,), stride=(1,))\n",
       "      (bn1): Bn_Relu(\n",
       "        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(16,), stride=(1,))\n",
       "    )\n",
       "    (13): Bn_Relu(\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (drop): Dropout(p=0.2)\n",
       "    )\n",
       "    (14): ResnetBlock(\n",
       "      (max1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv1): Conv1d(64, 64, kernel_size=(16,), stride=(2,))\n",
       "      (bn1): Bn_Relu(\n",
       "        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(16,), stride=(1,))\n",
       "    )\n",
       "    (15): Bn_Relu(\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (drop): Dropout(p=0.2)\n",
       "    )\n",
       "    (16): ResnetBlock(\n",
       "      (max1): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv1): Conv1d(64, 128, kernel_size=(16,), stride=(1,))\n",
       "      (bn1): Bn_Relu(\n",
       "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(16,), stride=(1,))\n",
       "    )\n",
       "    (17): Bn_Relu(\n",
       "      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (drop): Dropout(p=0.2)\n",
       "    )\n",
       "    (18): ResnetBlock(\n",
       "      (max1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(16,), stride=(2,))\n",
       "      (bn1): Bn_Relu(\n",
       "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(16,), stride=(1,))\n",
       "    )\n",
       "    (19): Bn_Relu(\n",
       "      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (drop): Dropout(p=0.2)\n",
       "    )\n",
       "    (20): ResnetBlock(\n",
       "      (max1): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(16,), stride=(1,))\n",
       "      (bn1): Bn_Relu(\n",
       "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(16,), stride=(1,))\n",
       "    )\n",
       "    (21): Bn_Relu(\n",
       "      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (drop): Dropout(p=0.2)\n",
       "    )\n",
       "    (22): ResnetBlock(\n",
       "      (max1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(16,), stride=(2,))\n",
       "      (bn1): Bn_Relu(\n",
       "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(16,), stride=(1,))\n",
       "    )\n",
       "    (23): Bn_Relu(\n",
       "      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (drop): Dropout(p=0.2)\n",
       "    )\n",
       "    (24): ResnetBlock(\n",
       "      (max1): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv1): Conv1d(128, 256, kernel_size=(16,), stride=(1,))\n",
       "      (bn1): Bn_Relu(\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(16,), stride=(1,))\n",
       "    )\n",
       "    (25): Bn_Relu(\n",
       "      (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (drop): Dropout(p=0.2)\n",
       "    )\n",
       "    (26): ResnetBlock(\n",
       "      (max1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv1): Conv1d(256, 256, kernel_size=(16,), stride=(2,))\n",
       "      (bn1): Bn_Relu(\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(16,), stride=(1,))\n",
       "    )\n",
       "    (27): Bn_Relu(\n",
       "      (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (drop): Dropout(p=0.2)\n",
       "    )\n",
       "    (28): ResnetBlock(\n",
       "      (max1): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv1): Conv1d(256, 256, kernel_size=(16,), stride=(1,))\n",
       "      (bn1): Bn_Relu(\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(16,), stride=(1,))\n",
       "    )\n",
       "    (29): Bn_Relu(\n",
       "      (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (drop): Dropout(p=0.2)\n",
       "    )\n",
       "    (30): ResnetBlock(\n",
       "      (max1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv1): Conv1d(256, 256, kernel_size=(16,), stride=(2,))\n",
       "      (bn1): Bn_Relu(\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(16,), stride=(1,))\n",
       "    )\n",
       "    (31): Bn_Relu(\n",
       "      (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (drop): Dropout(p=0.2)\n",
       "    )\n",
       "  )\n",
       "  (linear1): Linear(in_features=256, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(epoch,batchsize):\n",
    "    model.train()    \n",
    "    for epoch in range(epoch):\n",
    "        print('*'*10)\n",
    "        print('Epoch: {}'.format(epoch))\n",
    "        tloss = 0.0\n",
    "        taccu = 0.0\n",
    "        train_gen = data_generator(batchsize,train_x,train_y)\n",
    "        for x,y in train_gen:\n",
    "            #print (x.shape,y.shape)\n",
    "            inp = np.transpose(x, (0, 2, 1))\n",
    "            inp =torch.from_numpy(inp).requires_grad_()\n",
    "            inpTensor= inp.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inpTensor)\n",
    "            labels = torch.from_numpy(y).long()\n",
    "            labels = labels.cuda()\n",
    "            loss = loss_fn(outputs.view(outputs.shape[0]*outputs.shape[1],-1), labels.view(labels.shape[0]*labels.shape[1]))\n",
    "            tloss += loss.item()\n",
    "            pred = torch.max(outputs, -1)[1]\n",
    "            taccu += (pred == labels).sum().item()\n",
    "            #print(\"loss \", loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print('Loss: {}'.format(tloss))\n",
    "        print('Accu: {}'.format(taccu/len(train_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ValidateModel(batchsize):\n",
    "    model.eval()\n",
    "    tloss = 0.0\n",
    "    taccu = 0.0\n",
    "    valid_gen = data_generator(batchsize,valid_x,valid_y)\n",
    "    for x,y in valid_gen:\n",
    "        inp = np.transpose(x, (0, 2, 1))\n",
    "        inp =torch.from_numpy(inp)\n",
    "        inpTensor= inp.cuda()\n",
    "        outputs = model(inpTensor)\n",
    "        labels = torch.from_numpy(y).long()\n",
    "        labels = labels.cuda()\n",
    "        loss = loss_fn(outputs.view(outputs.shape[0]*outputs.shape[1],-1), labels.view(labels.shape[0]*labels.shape[1]))\n",
    "        tloss += loss.item()\n",
    "        pred = torch.max(outputs, -1)[1]\n",
    "        taccu += (pred == labels).sum().item()\n",
    "    print('Loss: {}'.format(tloss))\n",
    "    print('Accu: {}'.format(taccu/len(valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(852, 18176, 1) (852, 71)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('valid.npz')\n",
    "valid_x = data['a']\n",
    "valid_y = data['b']\n",
    "print(valid_x.shape,valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"test-1.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Epoch: 0\n",
      "Loss: 377056.09240722656\n",
      "Accu: 50.060838978634706\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "TrainModel(1,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Epoch: 0\n",
      "Loss: 271993.95275878906\n",
      "Accu: 55.935513288170924\n"
     ]
    }
   ],
   "source": [
    "TrainModel(1,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 30984.485260009766\n",
      "Accu: 54.40492957746479\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "ValidateModel(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"test-1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Epoch: 0\n",
      "Loss: 193934.66807556152\n",
      "Accu: 60.43564356435643\n",
      "**********\n",
      "Epoch: 1\n",
      "Loss: 190329.93565368652\n",
      "Accu: 60.642391870766026\n",
      "**********\n",
      "Epoch: 2\n",
      "Loss: 186438.39692687988\n",
      "Accu: 60.667404898384575\n",
      "**********\n",
      "Epoch: 3\n",
      "Loss: 179197.81770324707\n",
      "Accu: 61.37428348097968\n",
      "**********\n",
      "Epoch: 4\n",
      "Loss: 177761.2780456543\n",
      "Accu: 61.36933298593017\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "TrainModel(5,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 19819.917793273926\n",
      "Accu: 61.389671361502344\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "ValidateModel(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"test-1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Epoch: 0\n",
      "Loss: 170883.05847930908\n",
      "Accu: 61.93720687858259\n",
      "**********\n",
      "Epoch: 1\n",
      "Loss: 168821.39450073242\n",
      "Accu: 61.99231370505471\n",
      "**********\n",
      "Epoch: 2\n",
      "Loss: 163004.5175704956\n",
      "Accu: 62.45909327774883\n",
      "**********\n",
      "Epoch: 3\n",
      "Loss: 161507.6676864624\n",
      "Accu: 62.4254820218864\n",
      "**********\n",
      "Epoch: 4\n",
      "Loss: 155492.19296264648\n",
      "Accu: 62.84158415841584\n",
      "**********\n",
      "Epoch: 5\n",
      "Loss: 154064.56114196777\n",
      "Accu: 62.794424179260034\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "TrainModel(6,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 17882.455078125\n",
      "Accu: 62.082159624413144\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "ValidateModel(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"test-1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Epoch: 0\n",
      "Loss: 151394.92232513428\n",
      "Accu: 62.98449713392392\n",
      "**********\n",
      "Epoch: 1\n",
      "Loss: 148370.0378189087\n",
      "Accu: 63.238535695674834\n",
      "**********\n",
      "Epoch: 2\n",
      "Loss: 145475.99559020996\n",
      "Accu: 63.44971339239187\n",
      "**********\n",
      "Epoch: 3\n",
      "Loss: 143407.31893920898\n",
      "Accu: 63.52579468473163\n",
      "**********\n",
      "Epoch: 4\n",
      "Loss: 141174.9951095581\n",
      "Accu: 63.601875977071394\n",
      "**********\n",
      "Epoch: 5\n",
      "Loss: 137675.82921600342\n",
      "Accu: 63.76341844710787\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "TrainModel(6,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 17813.987754821777\n",
      "Accu: 62.35798122065728\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "ValidateModel(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"test-2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"test-2.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Epoch: 0\n",
      "Loss: 136388.07900238037\n",
      "Accu: 63.86099531005732\n",
      "**********\n",
      "Epoch: 1\n",
      "Loss: 132161.95597076416\n",
      "Accu: 64.10265763418447\n",
      "**********\n",
      "Epoch: 2\n",
      "Loss: 131530.73462677002\n",
      "Accu: 64.1323606044815\n",
      "**********\n",
      "Epoch: 3\n",
      "Loss: 129756.62490463257\n",
      "Accu: 64.34236581552892\n",
      "**********\n",
      "Epoch: 4\n",
      "Loss: 126288.5089263916\n",
      "Accu: 64.35330901511203\n",
      "**********\n",
      "Epoch: 5\n",
      "Loss: 126232.15660095215\n",
      "Accu: 64.3882230328296\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "TrainModel(6,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 15539.197761535645\n",
      "Accu: 63.617370892018776\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "ValidateModel(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"test-2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
